import asyncio
import logging
import argparse
import os
import time

# Tinker æ ¸å¿ƒåº“
import tinker
from tinker_cookbook.tokenizer_utils import get_tokenizer
from tinker_cookbook.renderers import get_renderer
from tinker_cookbook.model_info import get_recommended_renderer_name
# Image Processor
from tinker_cookbook.image_processing_utils import get_image_processor

# å¯¼å…¥ Environment
from env import BrowserEnv, BrowserTask, BrowserPool

# API Key
os.environ['TINKER_API_KEY'] = 'tml-Wrcd7jkyejehmtjAfQ8uUgyfyWtOwWQX8GCIqI6esrtLfD0FxsT6AiISJ5OPGovmjAAAA'

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def run_single_episode(args):
    # 1. åˆå§‹åŒ– Service
    service_client = tinker.ServiceClient()
    logger.info(f"Connected to Tinker Service. Model: {args.model_name}")

    sampling_client = service_client.create_sampling_client(
        base_model=args.model_name
    )

    # 2. æœ¬åœ°ç»„ä»¶
    tokenizer = get_tokenizer(args.model_name)
    logger.info("Loading Image Processor...")
    image_processor = get_image_processor(args.model_name)

    renderer_name = args.renderer_name or get_recommended_renderer_name(args.model_name)
    logger.info(f"Initializing Renderer: {renderer_name}")

    renderer = get_renderer(
        renderer_name,
        tokenizer=tokenizer,
        image_processor=image_processor
    )

    # 3. ç¯å¢ƒåˆå§‹åŒ–
    task = BrowserTask(
        id="test_cloud",
        goal=args.goal,
        start_url=args.url
    )
    pool = BrowserPool(headless=False)
    env = BrowserEnv(task, renderer, text_only=args.text_only, pool=pool)

    print(f"\nğŸš€ Starting Task: {task.goal}")
    print(f"ğŸŒ URL: {task.start_url}")
    print("-" * 50)

    try:
        # è·å– ModelInput
        obs, stop_condition = await env.initial_observation()

        done = False
        step_count = 0
        max_steps = 3

        while not done and step_count < max_steps:
            step_count += 1
            print(f"\n[Step {step_count}] Requesting Remote Inference...")

            # =================================================================
            # 4. æ¨¡å‹æ¨ç† (Fix: å‚æ•°é…ç½®ä¸ç»“æœæå–)
            # =================================================================

            # æ„é€  SamplingParams
            # æ³¨æ„ï¼šæ ¹æ® Tinker ç‰ˆæœ¬ä¸åŒï¼Œå‚æ•°åå¯èƒ½æ˜¯ stop æˆ– stop_sequences
            # åªè¦ä¹‹å‰æ²¡æŠ¥å‚æ•°é”™è¯¯ï¼Œè¯´æ˜ stop_sequences æ˜¯å¯¹çš„
            params = tinker.SamplingParams(
                max_tokens=128,
                temperature=0.0,
                stop_sequences=stop_condition
            )

            start_time = time.time()
            # è°ƒç”¨ sample()
            future = sampling_client.sample(
                prompt=obs,
                sampling_params=params,
                num_samples=1
            )

            # è·å–ç»“æœ
            result = future.result()
            print(f"time used: {time.time() - start_time}")

            # --- å…³é”®ä¿®å¤ï¼šä» SampleResponse ä¸­æå– Token åºåˆ— ---
            # result æ˜¯ SampleResponse å¯¹è±¡
            # result.sequences æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæˆ‘ä»¬å–ç¬¬ä¸€ä¸ªé‡‡æ ·ç»“æœ
            # sequence.tokens æ‰æ˜¯çœŸæ­£çš„ Action (List[int])
            if not result.sequences:
                logger.error("No sequences returned from model!")
                break

            # æå–åŠ¨ä½œ (Token IDs)
            action = result.sequences[0].tokens

            # =================================================================
            # 5. è§£æä¸æ‰§è¡Œ
            # =================================================================

            # è§£ææ–‡æœ¬ç”¨äºæ‰“å° (ä¼ å…¥ Action åˆ—è¡¨ï¼Œè€Œä¸æ˜¯ Response å¯¹è±¡)
            (message, _) = renderer.parse_response(action)

            raw_content = message["content"]
            if isinstance(raw_content, list):
                model_output = "".join([x.get("text", "") for x in raw_content if x.get("type") == "text"])
            else:
                model_output = str(raw_content)

            print(f"ğŸ¤– Model Action: {model_output}")

            # 5. ç¯å¢ƒæ‰§è¡Œ (ä¼ å…¥ Action åˆ—è¡¨)
            step_result = await env.step(action)

            obs = step_result.next_observation
            done = step_result.episode_done
            reward = step_result.reward

            if done:
                print("-" * 50)
                status = "SUCCESS" if reward > 0 else "FAILED"
                print(f"ğŸ Episode Finished. Result: {status} (Reward: {reward})")

        if not done:
            print(f"âŒ Timed out after {max_steps} steps.")

    finally:
        env.browser.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_name", type=str, default="Qwen/Qwen3-VL-30B-A3B-Instruct",
                        help="Tinker å¹³å°ä¸Šçš„ Base Model ID")
    parser.add_argument("--renderer_name", type=str, default=None)
    parser.add_argument("--goal", type=str, default="Translate hello world to Chinese", help="ä»»åŠ¡ç›®æ ‡")
    parser.add_argument("--url", type=str, default="https://www.iciba.com/", help="èµ·å§‹URL")
    parser.add_argument("--text_only", action="store_true")

    args = parser.parse_args()

    asyncio.run(run_single_episode(args))